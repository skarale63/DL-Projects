{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d2f76d8",
   "metadata": {},
   "source": [
    "# IMAGE CLASSIFICATION PROBLEM\n",
    "#### By using CNN we classifying fashion apparel dresses into their type of dress. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1781f175",
   "metadata": {},
   "source": [
    "### Imported library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c962a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported required python and sklearn library\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "from skimage import filters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56fd69e",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af082d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_000000.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_000001.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_000002.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_000003.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_000004.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name  label\n",
       "0  Image_000000.jpg      8\n",
       "1  Image_000001.jpg      8\n",
       "2  Image_000002.jpg      8\n",
       "3  Image_000003.jpg      8\n",
       "4  Image_000004.jpg      8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_label.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aab99db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2166\n",
       "1      922\n",
       "2     2778\n",
       "3     4139\n",
       "4     2052\n",
       "5     2433\n",
       "6     6285\n",
       "7     3664\n",
       "8     2338\n",
       "9     3933\n",
       "10    1039\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05a430",
   "metadata": {},
   "source": [
    "### Creating Folder and Copy image as per label in to respective folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39940628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Folder = df[\\'label\\'].unique()\\nfor i in Folder:\\n    os.mkdir(\"C:/Users/S Karale/MLDL/internship projects/stylumia/DATA PREPARATION/{}\".format(i))'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Folder by label\n",
    "'''Folder = df['label'].unique()\n",
    "for i in Folder:\n",
    "    os.mkdir(\"C:/Users/S Karale/MLDL/internship projects/stylumia/DATA PREPARATION/{}\".format(i))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e80946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for j in Folder:   \\n    x=df[\\'file_name\\'][df[\\'label\\']==j]\\n    for k in x:\\n        img = io.imread(\"C:/Users/S Karale/MLDL/internship projects/stylumia/model/train/{}\".format(k))\\n        gaussian_img = filters.gaussian(img,sigma=2)\\n        io.imsave(\\'C:/Users/S Karale/MLDL/internship projects/stylumia/DATA PREPARATION/{}/{}\\'.format(j,k),gaussian_img)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy image as per label in to respective folder\n",
    "'''for j in Folder:   \n",
    "    x=df['file_name'][df['label']==j]\n",
    "    for k in x:\n",
    "        img = io.imread(\"C:/Users/S Karale/MLDL/internship projects/stylumia/model/train/{}\".format(k))\n",
    "        gaussian_img = filters.gaussian(img,sigma=2)\n",
    "        io.imsave('C:/Users/S Karale/MLDL/internship projects/stylumia/DATA PREPARATION/{}/{}'.format(j,k),gaussian_img)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff682117",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12206e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu', input_shape = (64,64, 3)))\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(11, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04319622",
   "metadata": {},
   "source": [
    "### Train Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "203353fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescaling data\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aaf015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31451 images belonging to 11 classes.\n",
      "Found 31451 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "#Prepare train, test data \n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\S Karale\\MLDL\\internship projects\\stylumia\\DATA PREPARATION',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 128)\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\S Karale\\MLDL\\internship projects\\stylumia\\DATA PREPARATION',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0340c",
   "metadata": {},
   "source": [
    "### Fit Data into Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f7d5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 194s 10s/step - loss: 0.3838 - accuracy: 0.1582 - val_loss: 0.3041 - val_accuracy: 0.1488\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 180s 9s/step - loss: 0.2993 - accuracy: 0.1914 - val_loss: 0.2955 - val_accuracy: 0.2012\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 185s 9s/step - loss: 0.2950 - accuracy: 0.1996 - val_loss: 0.2948 - val_accuracy: 0.1871\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 181s 9s/step - loss: 0.2942 - accuracy: 0.2012 - val_loss: 0.2948 - val_accuracy: 0.1883\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 183s 9s/step - loss: 0.2941 - accuracy: 0.1922 - val_loss: 0.2937 - val_accuracy: 0.2020\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 181s 9s/step - loss: 0.2932 - accuracy: 0.1941 - val_loss: 0.2923 - val_accuracy: 0.2039\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 179s 9s/step - loss: 0.2923 - accuracy: 0.2045 - val_loss: 0.2914 - val_accuracy: 0.2090\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 177s 9s/step - loss: 0.2941 - accuracy: 0.1988 - val_loss: 0.2914 - val_accuracy: 0.1941\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 182s 9s/step - loss: 0.2909 - accuracy: 0.2164 - val_loss: 0.2917 - val_accuracy: 0.2105\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 185s 9s/step - loss: 0.2913 - accuracy: 0.2113 - val_loss: 0.2907 - val_accuracy: 0.1957\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 182s 9s/step - loss: 0.2888 - accuracy: 0.2074 - val_loss: 0.2920 - val_accuracy: 0.2137\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 182s 9s/step - loss: 0.2887 - accuracy: 0.2211 - val_loss: 0.2891 - val_accuracy: 0.2355\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 182s 9s/step - loss: 0.2888 - accuracy: 0.2324 - val_loss: 0.2848 - val_accuracy: 0.2406\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 180s 9s/step - loss: 0.2875 - accuracy: 0.2133 - val_loss: 0.2884 - val_accuracy: 0.2379\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 179s 9s/step - loss: 0.2901 - accuracy: 0.2137 - val_loss: 0.2883 - val_accuracy: 0.2430\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 137s 7s/step - loss: 0.2873 - accuracy: 0.2402 - val_loss: 0.2889 - val_accuracy: 0.2160\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 120s 6s/step - loss: 0.2878 - accuracy: 0.2289 - val_loss: 0.2857 - val_accuracy: 0.2418\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 117s 6s/step - loss: 0.2865 - accuracy: 0.2363 - val_loss: 0.2816 - val_accuracy: 0.2598\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 117s 6s/step - loss: 0.2861 - accuracy: 0.2344 - val_loss: 0.2823 - val_accuracy: 0.2500\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 121s 6s/step - loss: 0.2852 - accuracy: 0.2367 - val_loss: 0.2835 - val_accuracy: 0.2488\n"
     ]
    }
   ],
   "source": [
    "model1 = model.fit(training_set,\n",
    "                    steps_per_epoch = 20,\n",
    "                    epochs = 20,\n",
    "                    validation_data = test_set,    \n",
    "                    validation_steps =20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee9870",
   "metadata": {},
   "source": [
    "###### for model1 loss is 0.2458 and accuracy is 0.3801"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf1bff",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13cf2fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Image_test_000000.jpg\n",
       "1    Image_test_000001.jpg\n",
       "2    Image_test_000002.jpg\n",
       "3    Image_test_000003.jpg\n",
       "4    Image_test_000004.jpg\n",
       "Name: file_name, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.evaluate(test_set)\n",
    "df_test = pd.read_csv('sample_submission.csv')\n",
    "df2 = df_test['file_name']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24557a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "file_name_list = []\n",
    "for m in df2:\n",
    "    test_image = image.load_img(\"C:/Users/S Karale/MLDL/internship projects/stylumia/test/{}\".format(m), target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = model.predict(test_image)\n",
    "    for n in list(range(11)):\n",
    "        if result[0][n] == 1:\n",
    "            prediction = n\n",
    "            label_list.append(prediction)\n",
    "            file_name_list.append(m)\n",
    "        elif result[0][n] >= 0.5:\n",
    "            prediction = n\n",
    "            label_list.append(prediction)\n",
    "            file_name_list.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfa2529",
   "metadata": {},
   "source": [
    "### Build a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7509f4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Image_test_000000.jpg</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_test_000001.jpg</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_test_000002.jpg</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_test_000003.jpg</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_test_000004.jpg</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label\n",
       "file_name                   \n",
       "Image_test_000000.jpg      7\n",
       "Image_test_000001.jpg      7\n",
       "Image_test_000002.jpg      7\n",
       "Image_test_000003.jpg      7\n",
       "Image_test_000004.jpg      8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build and save test submission file in csv format\n",
    "disc = {'file_name':file_name_list,'label':label_list}\n",
    "df4 = pd.DataFrame(disc)\n",
    "df4.set_index(\"file_name\", inplace = True)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66d396f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('test_submission_file1_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc9711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
